{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "u_OIwDav0A4W"
      },
      "outputs": [],
      "source": [
        "# Copyright 2024 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T_oWMJLg0fLk"
      },
      "source": [
        "# Quick start with Model Garden - CXR Foundation\n",
        "\n",
        "<table><tbody><tr>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://console.cloud.google.com/vertex-ai/colab/import/https:%2F%2Fraw.githubusercontent.com%2Fgoogle-health%2Fcxr-foundation%2Fmaster%2Fnotebooks%2Fquick_start_with_model_garden.ipynb\">\n",
        "      <img alt=\"Google Cloud Colab Enterprise logo\" src=\"https://lh3.googleusercontent.com/JmcxdQi-qOpctIvWKgPtrzZdJJK-J3sWE1RsfjZNwshCFgE_9fULcNpuXYTilIR2hjwN\" width=\"32px\"><br> Run in Colab Enterprise\n",
        "    </a>\n",
        "  </td>\n",
        "  <td style=\"text-align: center\">\n",
        "    <a href=\"https://github.com/google-health/cxr-foundation/blob/master/notebooks/quick_start_with_model_garden.ipynb\">\n",
        "      <img alt=\"GitHub logo\" src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" width=\"32px\"><br> View on GitHub\n",
        "    </a>\n",
        "  </td>\n",
        "</tr></tbody></table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JsEU-DK7DJcv"
      },
      "source": [
        "## Overview\n",
        "\n",
        "This notebook demonstrates deploying CXR Foundation to Vertex AI and making online or batch predictions to get embeddings from chest X-ray images or text.\n",
        "\n",
        "Vertex AI makes it easy to serve your model and make it accessible to the world. Learn more about [Vertex AI]((https://cloud.google.com/vertex-ai/docs/start/introduction-unified-platform).\n",
        "\n",
        "\n",
        "### Objectives\n",
        "\n",
        "- Deploy CXR Foundation to a Vertex AI Endpoint and get online predictions.\n",
        "- Upload CXR Foundation to Vertex AI Model Registry and get batch predictions.\n",
        "\n",
        "### Costs\n",
        "\n",
        "This tutorial uses billable components of Google Cloud:\n",
        "\n",
        "* Vertex AI\n",
        "* Cloud Storage\n",
        "\n",
        "Learn about [Vertex AI pricing](https://cloud.google.com/vertex-ai/pricing), [Cloud Storage pricing](https://cloud.google.com/storage/pricing), and use the [Pricing Calculator](https://cloud.google.com/products/calculator/) to generate a cost estimate based on your projected usage."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fe_iHV1RDA3C"
      },
      "source": [
        "## Before you begin"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "7NnO9sDyV1eI"
      },
      "outputs": [],
      "source": [
        "# @title Import packages and define common functions\n",
        "\n",
        "! git clone https://github.com/GoogleCloudPlatform/vertex-ai-samples.git\n",
        "\n",
        "import datetime\n",
        "import importlib\n",
        "import io\n",
        "import json\n",
        "import os\n",
        "import uuid\n",
        "\n",
        "import numpy as np\n",
        "from google.cloud import aiplatform, storage\n",
        "from google.oauth2 import credentials\n",
        "from PIL import Image\n",
        "\n",
        "common_util = importlib.import_module(\n",
        "    \"vertex-ai-samples.community-content.vertex_model_garden.model_oss.notebook_util.common_util\"\n",
        ")\n",
        "\n",
        "models, endpoints = {}, {}\n",
        "\n",
        "\n",
        "def download_gcs_image_bytes(gcs_uri, creds):\n",
        "    \"\"\"Download an image from Cloud Storage.\"\"\"\n",
        "    storage_client = storage.Client(credentials=creds)\n",
        "    blob = storage.blob.Blob.from_string(gcs_uri, client=storage_client)\n",
        "    return blob.download_as_bytes()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "2_aYhzoEDMCf"
      },
      "outputs": [],
      "source": [
        "# @title Set up Google Cloud project\n",
        "\n",
        "# @markdown 1. [Make sure that billing is enabled for your project](https://cloud.google.com/billing/docs/how-to/modify-project).\n",
        "\n",
        "# @markdown 2. Make sure that you have the following required roles:\n",
        "# @markdown - [Storage Admin](https://cloud.google.com/iam/docs/understanding-roles#storage.admin) (`roles/storage.admin`) to create and use Cloud Storage buckets\n",
        "# @markdown - [Service Usage Admin](https://cloud.google.com/iam/docs/understanding-roles#serviceusage.serviceUsageAdmin) (`roles/serviceusage.serviceUsageAdmin`) to enable necessary APIs\n",
        "\n",
        "# @markdown 3. Set up a [Cloud Storage bucket](https://cloud.google.com/storage/docs/creating-buckets).\n",
        "# @markdown - A new bucket will be set up for you to store artifacts used in this notebook.\n",
        "# @markdown - [Optional] To use an existing bucket, specify the `gs://` bucket URI. The specified Cloud Storage bucket should be located in the same region as where the notebook was launched. Note that a multi-region bucket (e.g. \"us\") is not considered a match for a single region covered by the multi-region range (e.g. \"us-central1\").\n",
        "\n",
        "BUCKET_URI = \"\"  # @param {type:\"string\", placeholder:\"[Optional] Cloud Storage bucket URI\"}\n",
        "\n",
        "# The region will be set automatically according to the Colab Enterprise environment.\n",
        "REGION = \"\"\n",
        "\n",
        "\n",
        "# Get the default cloud project id.\n",
        "PROJECT_ID = os.environ[\"GOOGLE_CLOUD_PROJECT\"]\n",
        "\n",
        "# Get the default region for launching jobs.\n",
        "if not REGION:\n",
        "    REGION = os.environ[\"GOOGLE_CLOUD_REGION\"]\n",
        "\n",
        "# Enable the Vertex AI API and Compute Engine API, if not already.\n",
        "print(\"Enabling Vertex AI API and Compute Engine API.\")\n",
        "! gcloud services enable aiplatform.googleapis.com compute.googleapis.com\n",
        "\n",
        "# Cloud Storage bucket for storing the experiment artifacts.\n",
        "# A unique GCS bucket will be created for the purpose of this notebook. If you\n",
        "# prefer using your own GCS bucket, change the value yourself below.\n",
        "now = datetime.datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
        "BUCKET_NAME = \"/\".join(BUCKET_URI.split(\"/\")[:3])\n",
        "\n",
        "if BUCKET_URI is None or BUCKET_URI.strip() == \"\" or BUCKET_URI == \"gs://\":\n",
        "    BUCKET_URI = f\"gs://{PROJECT_ID}-tmp-{now}-{str(uuid.uuid4())[:4]}\"\n",
        "    BUCKET_NAME = \"/\".join(BUCKET_URI.split(\"/\")[:3])\n",
        "    ! gsutil mb -l {REGION} {BUCKET_URI}\n",
        "else:\n",
        "    assert BUCKET_URI.startswith(\"gs://\"), \"BUCKET_URI must start with `gs://`.\"\n",
        "    shell_output = ! gsutil ls -Lb {BUCKET_NAME} | grep \"Location constraint:\" | sed \"s/Location constraint://\"\n",
        "    bucket_region = shell_output[0].strip().lower()\n",
        "    if bucket_region != REGION:\n",
        "        raise ValueError(\n",
        "            \"Bucket region %s is different from notebook region %s\"\n",
        "            % (bucket_region, REGION)\n",
        "        )\n",
        "print(f\"Using this GCS Bucket: {BUCKET_URI}\")\n",
        "\n",
        "STAGING_BUCKET = os.path.join(BUCKET_URI, \"temporal\")\n",
        "MODEL_BUCKET = os.path.join(BUCKET_URI, \"cxr-foundation\")\n",
        "\n",
        "\n",
        "# Initialize Vertex AI API.\n",
        "print(\"Initializing Vertex AI API.\")\n",
        "aiplatform.init(project=PROJECT_ID, location=REGION, staging_bucket=STAGING_BUCKET)\n",
        "\n",
        "# Gets the default SERVICE_ACCOUNT.\n",
        "shell_output = ! gcloud projects describe $PROJECT_ID\n",
        "project_number = shell_output[-1].split(\":\")[1].strip().replace(\"'\", \"\")\n",
        "SERVICE_ACCOUNT = f\"{project_number}-compute@developer.gserviceaccount.com\"\n",
        "print(\"Using this default Service Account:\", SERVICE_ACCOUNT)\n",
        "\n",
        "\n",
        "# Provision permissions to the SERVICE_ACCOUNT with the GCS bucket\n",
        "! gsutil iam ch serviceAccount:{SERVICE_ACCOUNT}:roles/storage.admin $BUCKET_NAME\n",
        "\n",
        "! gcloud config set project $PROJECT_ID\n",
        "! gcloud projects add-iam-policy-binding --no-user-output-enabled {PROJECT_ID} --member=serviceAccount:{SERVICE_ACCOUNT} --role=\"roles/storage.admin\"\n",
        "! gcloud projects add-iam-policy-binding --no-user-output-enabled {PROJECT_ID} --member=serviceAccount:{SERVICE_ACCOUNT} --role=\"roles/aiplatform.user\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jIQWIkbWN4Pr"
      },
      "source": [
        "## Get online predictions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "scIui-UmGPJy"
      },
      "outputs": [],
      "source": [
        "# @title #### Import deployed model\n",
        "\n",
        "# @markdown To get [online predictions](https://cloud.google.com/vertex-ai/docs/predictions/get-online-predictions), you will need a CXR Foundation [Vertex AI Endpoint](https://cloud.google.com/vertex-ai/docs/general/deployment) that has been deployed from Model Garden. If you have not already done so, go to the [CXR Foundation model card](https://console.cloud.google.com/vertex-ai/publishers/google/model-garden/cxr-foundation) in Model Garden and click \"Deploy\" to deploy the model.\n",
        "\n",
        "# @markdown This section gets the Vertex AI Endpoint resource that you deployed from Model Garden to use for online predictions.\n",
        "\n",
        "# @markdown Fill in the endpoint ID and region below. You can find your deployed endpoint on the [Vertex AI online prediction page](https://console.cloud.google.com/vertex-ai/online-prediction/endpoints).\n",
        "\n",
        "ENDPOINT_ID = \"\"  # @param {type: \"string\", placeholder:\"e.g. 123456789\"}\n",
        "ENDPOINT_REGION = \"\"  # @param {type: \"string\", placeholder:\"e.g. us-central1\"}\n",
        "\n",
        "endpoints[\"endpoint\"] = aiplatform.Endpoint(\n",
        "    endpoint_name=ENDPOINT_ID,\n",
        "    project=PROJECT_ID,\n",
        "    location=ENDPOINT_REGION,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cWEgmqO8N-T7"
      },
      "source": [
        "### Predict\n",
        "\n",
        "You can send [online prediction requests](https://cloud.google.com/vertex-ai/docs/predictions/get-online-predictions#predict-request) to the endpoint with chest X-ray images or text to generate embeddings.\n",
        "\n",
        "The following examples illustrate how to use CXR Foundation to generate:\n",
        "\n",
        "* Image embeddings from\n",
        "  * An image or a DICOM file stored in [Cloud Storage](https://cloud.google.com/storage/docs)\n",
        "  * A DICOM instance stored in [Cloud Healthcare DICOM Store](https://cloud.google.com/healthcare-api/docs/how-tos/dicom)\n",
        "  * Base64-encoded image bytes\n",
        "* Text embeddings from a text query\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "trU5YDBEHwn-"
      },
      "outputs": [],
      "source": [
        "# @title #### Generate an embedding from an image or DICOM file in Cloud Storage\n",
        "\n",
        "# @markdown This section shows an example of generating an embedding using an image from the [CXR Foundation Demo Cloud Storage bucket](https://console.cloud.google.com/storage/browser/cxr-foundation-demo), which contains a subset of the NIH Chest X-ray14 dataset [[1]](#scrollTo=k3asO-u59c9Q).\n",
        "\n",
        "# @markdown The prediction request instance contains the following fields:\n",
        "# @markdown - `gcs_uri`: `gs://` URI specifying the location of an image or DICOM file stored in Cloud Storage\n",
        "# @markdown - `bearer_token`: Bearer token used to access data in Cloud Storage (optional for public buckets)\n",
        "\n",
        "# @markdown You can replace `GCS_URI` below to use your own data.\n",
        "\n",
        "# @markdown Click \"Show Code\" to see more details.\n",
        "\n",
        "GCS_URI = \"gs://cxr-foundation-demo/cxr14/inputs/00000001_000.dcm\"  # @param {type:\"string\", placeholder:\"Cloud Storage file URI\"}\n",
        "\n",
        "bearer_token = ! gcloud auth print-access-token\n",
        "bearer_token = bearer_token[0]\n",
        "creds = credentials.Credentials(token=bearer_token)\n",
        "\n",
        "_, file_ext = os.path.splitext(GCS_URI)\n",
        "if file_ext == \".dcm\":\n",
        "    # Displaying a DICOM image is not supported\n",
        "    pass\n",
        "else:\n",
        "    creds = credentials.Credentials(token=bearer_token)\n",
        "    img = Image.open(io.BytesIO(download_gcs_image_bytes(GCS_URI, creds))).convert(\n",
        "        \"L\"\n",
        "    )  # Convert to grayscale\n",
        "    display(img)\n",
        "\n",
        "instances = [\n",
        "    {\n",
        "        \"gcs_uri\": GCS_URI,\n",
        "        \"bearer_token\": bearer_token,\n",
        "    },\n",
        "]\n",
        "\n",
        "\n",
        "response = endpoints[\"endpoint\"].predict(instances=instances)\n",
        "predictions = response.predictions\n",
        "\n",
        "img_embedding = np.array(predictions[0][\"contrastive_img_emb\"])\n",
        "\n",
        "print(\"Embedding shape: \", img_embedding.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "6bXfTwaPht7P"
      },
      "outputs": [],
      "source": [
        "# @title #### Generate an embedding from a DICOM instance\n",
        "\n",
        "# @markdown This section shows an example of generating an embedding using a DICOM\n",
        "# @markdown instance stored in a Cloud Healthcare DICOM Store.\n",
        "\n",
        "# @markdown The prediction request instance contains the following fields:\n",
        "# @markdown - `dicomweb_uri`: [DICOMweb](https://cloud.google.com/healthcare-api/docs/how-tos/dicomweb) URI specifying the location of a DICOM instance stored in DICOM store\n",
        "# @markdown - `bearer_token`: Bearer token used to access data in DICOM store (optional for public data)\n",
        "\n",
        "# @markdown A sample DICOM instance is not provided. Specify `DICOMWEB_URI` below to use your own data.\n",
        "\n",
        "# @markdown Click \"Show Code\" to see more details.\n",
        "\n",
        "DICOMWEB_URI = \"https://healthcare.googleapis.com/v1/projects/PROJECT_ID/locations/LOCATION/datasets/DATASET_ID/dicomStores/DICOM_STORE_ID/dicomWeb/studies/STUDY_INSTANCE_UID/series/SERIES_INSTANCE_UID/instances/INSTANCE_UID\"  # @param {type:\"string\", placeholder:\"DICOM instance URI\"}\n",
        "\n",
        "bearer_token = ! gcloud auth print-access-token\n",
        "bearer_token = bearer_token[0]\n",
        "\n",
        "instances = [\n",
        "    {\n",
        "        \"dicomweb_uri\": DICOMWEB_URI,\n",
        "        \"bearer_token\": bearer_token,\n",
        "    },\n",
        "]\n",
        "\n",
        "response = endpoints[\"endpoint\"].predict(instances=instances)\n",
        "predictions = response.predictions\n",
        "\n",
        "img_embedding = np.array(predictions[0][\"contrastive_img_emb\"])\n",
        "\n",
        "print(\"Embedding shape: \", img_embedding.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "7WuL-IUJgzkJ"
      },
      "outputs": [],
      "source": [
        "# @title #### Generate an embedding from image bytes\n",
        "\n",
        "# @markdown This section shows an example of generating an embedding using a chest X-ray image from Wikimedia Commons [[2]](#scrollTo=k3asO-u59c9Q) that is downloaded as image bytes.\n",
        "\n",
        "# @markdown The prediction request instance contains the following field:\n",
        "# @markdown - `input_bytes`: Base-64 encoded image bytes\n",
        "\n",
        "# @markdown **Note:** Prediction requests to public endpoints (e.g. endpoints deployed from Model Garden) [must be 1.5 MB or smaller](https://cloud.google.com/vertex-ai/docs/predictions/get-online-predictions#send-request), so this example uses a lower resolution image.\n",
        "\n",
        "# @markdown Click \"Show Code\" to see more details.\n",
        "\n",
        "image_url = \"https://upload.wikimedia.org/wikipedia/commons/thumb/c/c8/Chest_Xray_PA_3-8-2010.png/1024px-Chest_Xray_PA_3-8-2010.png\"\n",
        "! wget -nc -q {image_url}\n",
        "img = Image.open(\"1024px-Chest_Xray_PA_3-8-2010.png\").convert(\n",
        "    \"L\"\n",
        ")  # Convert to grayscale\n",
        "display(img)\n",
        "instances = [{\"input_bytes\": common_util.image_to_base64(img, \"PNG\")}]\n",
        "\n",
        "response = endpoints[\"endpoint\"].predict(instances=instances)\n",
        "predictions = response.predictions\n",
        "\n",
        "img_embedding = np.array(predictions[0][\"contrastive_img_emb\"])\n",
        "\n",
        "print(\"Embedding shape: \", img_embedding.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "odmyYn1HHHaY"
      },
      "outputs": [],
      "source": [
        "# @title #### Generate an embedding from a text query\n",
        "\n",
        "# @markdown This section shows an example of generating an embedding from a text query.\n",
        "\n",
        "# @markdown The prediction request instance contains the following field:\n",
        "# @markdown - `prompt_query`: Text query string\n",
        "\n",
        "# @markdown Click \"Show Code\" to see more details.\n",
        "\n",
        "PROMPT_QUERY = \"Airspace opacity\"  # @param {type:\"string\", placeholder:\"Text query string\"}\n",
        "\n",
        "instances = [{\"prompt_query\": PROMPT_QUERY}]\n",
        "\n",
        "response = endpoints[\"endpoint\"].predict(instances=instances)\n",
        "predictions = response.predictions\n",
        "\n",
        "txt_embedding = np.array(predictions[0][\"contrastive_txt_emb\"])\n",
        "\n",
        "print(\"Embedding shape: \", txt_embedding.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ql6orPSzXnIV"
      },
      "source": [
        "## Get batch predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "EeIIG5OUNWn8"
      },
      "outputs": [],
      "source": [
        "# @title Upload model to Vertex AI Model Registry\n",
        "\n",
        "# @markdown To get [batch predictions](https://cloud.google.com/vertex-ai/docs/predictions/get-batch-predictions), you must first upload the prebuilt CXR Foundation model to [Vertex AI Model Registry](https://cloud.google.com/vertex-ai/docs/model-registry/introduction). Batch predictions are made directly on a model in Model Registry without deploying to an endpoint.\n",
        "\n",
        "MODEL_ID = \"cxr-foundation\"\n",
        "MODEL_ARTIFACT_URI = \"gs://vertex-model-garden-restricted-us/cxr-foundation\"\n",
        "\n",
        "# The pre-built serving docker image.\n",
        "SERVE_DOCKER_URI = \"us-docker.pkg.dev/deeplearning-platform-release/vertex-model-garden/health-ai-cxr-foundation.cpu.1-0.ubuntu2004.py312.tf218:20241118-1537-rc0\"\n",
        "\n",
        "\n",
        "def upload_model(model_name: str, artifact_uri: str) -> aiplatform.Model:\n",
        "    model = aiplatform.Model.upload(\n",
        "        display_name=model_name,\n",
        "        artifact_uri=artifact_uri,\n",
        "        serving_container_image_uri=SERVE_DOCKER_URI,\n",
        "        serving_container_ports=[8080],\n",
        "        serving_container_predict_route=\"/predict\",\n",
        "        serving_container_health_route=\"/health\",\n",
        "    )\n",
        "    return model\n",
        "\n",
        "\n",
        "models[\"model\"] = upload_model(\n",
        "    model_name=common_util.get_job_name_with_datetime(prefix=MODEL_ID),\n",
        "    artifact_uri=MODEL_ARTIFACT_URI,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sgJ0FuJ17_Vu"
      },
      "source": [
        "### Predict\n",
        "\n",
        "You can send [batch prediction requests](https://cloud.google.com/vertex-ai/docs/predictions/get-batch-predictions#request_a_batch_prediction) to the model using a [JSON Lines](https://jsonlines.org/) file to specify a list of input instances with chest X-ray images or text to generate embeddings.\n",
        "\n",
        "The following examples illustrate how to use CXR Foundation to generate:\n",
        "\n",
        "* Image embeddings in batch from\n",
        "  * An image or a DICOM file stored in [Cloud Storage](https://cloud.google.com/storage/docs)\n",
        "  * A DICOM instance stored in [Cloud Healthcare DICOM Store](https://cloud.google.com/healthcare-api/docs/how-tos/dicom)\n",
        "  * Base64-encoded image bytes\n",
        "* Text embeddings in batch from a text query"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Qpfs5eQVXotB"
      },
      "outputs": [],
      "source": [
        "# @title #### Generate embeddings in batch from image or DICOM files in Cloud Storage\n",
        "\n",
        "# @markdown This section shows an example of generating embeddings in batch using images from the [CXR Foundation Demo Cloud Storage bucket](https://console.cloud.google.com/storage/browser/cxr-foundation-demo), which contains a subset of the NIH Chest X-ray14 dataset [[1]](#scrollTo=k3asO-u59c9Q).\n",
        "\n",
        "# @markdown Each line in the input JSON Lines file is a prediction request instance that contains the following field:\n",
        "# @markdown - `gcs_uri`: `gs://` URI specifying the location of an image file stored in Cloud Storage\n",
        "\n",
        "# @markdown You can replace `GCS_URIS` below to use your own data.\n",
        "\n",
        "# @markdown **Note:** The custom service account used to launch the batch prediction job must have permission to read the data from Cloud Storage.\n",
        "\n",
        "# @markdown Click \"Show Code\" to see more details.\n",
        "\n",
        "# Comma-separated list of Cloud Storage URIs\n",
        "GCS_URIS = \"gs://cxr-foundation-demo/cxr14/inputs/00000001_000.dcm,gs://cxr-foundation-demo/cxr14/inputs/00000001_001.dcm\"  # @param {type:\"string\", placeholder:\"Comma-separated list of Cloud Storage file URIs\"}\n",
        "\n",
        "gcs_uris_list = GCS_URIS.split(\",\")\n",
        "batch_predict_instances = [{\"gcs_uri\": uri} for uri in gcs_uris_list]\n",
        "\n",
        "# Write instances to JSON Lines file\n",
        "os.makedirs(\"batch_predict_input\", exist_ok=True)\n",
        "instances_filename = \"gcs_instances.jsonl\"\n",
        "with open(f\"batch_predict_input/{instances_filename}\", \"w\") as f:\n",
        "    for line in batch_predict_instances:\n",
        "        json_str = json.dumps(line)\n",
        "        f.write(json_str)\n",
        "        f.write(\"\\n\")\n",
        "\n",
        "# Copy the file to Cloud Storage\n",
        "batch_predict_prefix = f\"batch-predict-{MODEL_ID}\"\n",
        "! gcloud storage cp ./batch_predict_input/{instances_filename} {STAGING_BUCKET}/{batch_predict_prefix}/input/{instances_filename}\n",
        "\n",
        "batch_predict_job_name = common_util.get_job_name_with_datetime(\n",
        "    prefix=f\"batch-predict-{MODEL_ID}\"\n",
        ")\n",
        "\n",
        "gcs_batch_predict_job = models[\"model\"].batch_predict(\n",
        "    job_display_name=batch_predict_job_name,\n",
        "    gcs_source=os.path.join(\n",
        "        STAGING_BUCKET, batch_predict_prefix, f\"input/{instances_filename}\"\n",
        "    ),\n",
        "    gcs_destination_prefix=os.path.join(STAGING_BUCKET, batch_predict_prefix, \"output\"),\n",
        "    machine_type=\"n1-highmem-8\",\n",
        "    service_account=SERVICE_ACCOUNT,\n",
        ")\n",
        "\n",
        "gcs_batch_predict_job.wait()\n",
        "\n",
        "print(gcs_batch_predict_job.display_name)\n",
        "print(gcs_batch_predict_job.resource_name)\n",
        "print(gcs_batch_predict_job.state)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "wnw97MNN8onS"
      },
      "outputs": [],
      "source": [
        "# @title #### Generate embeddings in batch from DICOM instances\n",
        "\n",
        "# @markdown This section shows an example of generating embeddings in batch using DICOM instances stored in a Cloud Healthcare DICOM Store.\n",
        "\n",
        "# @markdown Each line in the input JSON Lines file is a prediction request instance that contains the following field:\n",
        "# @markdown - `dicomweb_uri`: [DICOMweb](https://cloud.google.com/healthcare-api/docs/how-tos/dicomweb) URI specifying the location of a DICOM instance stored in DICOM store\n",
        "\n",
        "# @markdown Sample DICOM instances are not provided. Specify `DICOMWEB_URIS` below to use your own data.\n",
        "\n",
        "# @markdown **Note:** The custom service account used to launch the batch prediction job must have permission to read the data from DICOM store.\n",
        "\n",
        "# @markdown Click \"Show Code\" to see more details.\n",
        "\n",
        "# Comma-separated list of DICOMweb URIs\n",
        "DICOMWEB_URIS = \"https://healthcare.googleapis.com/v1/projects/PROJECT_ID/locations/LOCATION/datasets/DATASET_ID/dicomStores/DICOM_STORE_ID/dicomWeb/studies/STUDY_INSTANCE_UID/series/SERIES_INSTANCE_UID/instances/INSTANCE_UID\"  # @param {type:\"string\", placeholder:\"Comma-separated list of DICOM instance URIs\"}\n",
        "\n",
        "dicomweb_uris_list = DICOMWEB_URIS.split(\",\")\n",
        "batch_predict_instances = [{\"dicomweb_uri\": uri} for uri in dicomweb_uris_list]\n",
        "\n",
        "# Write instances to JSON Lines file\n",
        "os.makedirs(\"batch_predict_input\", exist_ok=True)\n",
        "instances_filename = \"dicom_instances.jsonl\"\n",
        "with open(f\"batch_predict_input/{instances_filename}\", \"w\") as f:\n",
        "    for line in batch_predict_instances:\n",
        "        json_str = json.dumps(line)\n",
        "        f.write(json_str)\n",
        "        f.write(\"\\n\")\n",
        "\n",
        "# Copy the file to Cloud Storage\n",
        "batch_predict_prefix = f\"batch-predict-{MODEL_ID}\"\n",
        "! gcloud storage cp ./batch_predict_input/{instances_filename} {STAGING_BUCKET}/{batch_predict_prefix}/input/{instances_filename}\n",
        "\n",
        "batch_predict_job_name = common_util.get_job_name_with_datetime(\n",
        "    prefix=f\"batch-predict-{MODEL_ID}\"\n",
        ")\n",
        "\n",
        "dicom_batch_predict_job = models[\"model\"].batch_predict(\n",
        "    job_display_name=batch_predict_job_name,\n",
        "    gcs_source=os.path.join(\n",
        "        STAGING_BUCKET, batch_predict_prefix, f\"input/{instances_filename}\"\n",
        "    ),\n",
        "    gcs_destination_prefix=os.path.join(STAGING_BUCKET, batch_predict_prefix, \"output\"),\n",
        "    machine_type=\"n1-highmem-8\",\n",
        "    service_account=SERVICE_ACCOUNT,\n",
        ")\n",
        "\n",
        "dicom_batch_predict_job.wait()\n",
        "\n",
        "print(dicom_batch_predict_job.display_name)\n",
        "print(dicom_batch_predict_job.resource_name)\n",
        "print(dicom_batch_predict_job.state)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "NrlOQWdsAAYn"
      },
      "outputs": [],
      "source": [
        "# @title #### Generate embeddings in batch from image bytes\n",
        "\n",
        "# @markdown This section shows an example of generating embeddings in batch using a chest X-ray image from Wikimedia Commons [[2]](#scrollTo=k3asO-u59c9Q) that is downloaded as image bytes.\n",
        "\n",
        "# @markdown Each line in the input JSON Lines file is a prediction request instance that contains the following field:\n",
        "# @markdown - `input_bytes`: Base-64 encoded image bytes\n",
        "\n",
        "# @markdown Click \"Show Code\" to see more details.\n",
        "\n",
        "image_urls = [\n",
        "    \"https://upload.wikimedia.org/wikipedia/commons/thumb/c/c8/Chest_Xray_PA_3-8-2010.png/1024px-Chest_Xray_PA_3-8-2010.png\"\n",
        "]\n",
        "batch_predict_instances = []\n",
        "for image_url in image_urls:\n",
        "    ! wget -nc -q {image_url}\n",
        "    img = Image.open(\"1024px-Chest_Xray_PA_3-8-2010.png\").convert(\n",
        "        \"L\"\n",
        "    )  # Convert to grayscale\n",
        "    batch_predict_instances.append(\n",
        "        {\"input_bytes\": common_util.image_to_base64(img, \"PNG\")}\n",
        "    )\n",
        "\n",
        "# Write instances to JSON Lines file\n",
        "os.makedirs(\"batch_predict_input\", exist_ok=True)\n",
        "instances_filename = \"bytes_instances.jsonl\"\n",
        "with open(f\"batch_predict_input/{instances_filename}\", \"w\") as f:\n",
        "    for line in batch_predict_instances:\n",
        "        json_str = json.dumps(line)\n",
        "        f.write(json_str)\n",
        "        f.write(\"\\n\")\n",
        "\n",
        "# Copy the file to Cloud Storage\n",
        "batch_predict_prefix = f\"batch-predict-{MODEL_ID}\"\n",
        "! gcloud storage cp ./batch_predict_input/{instances_filename} {STAGING_BUCKET}/{batch_predict_prefix}/input/{instances_filename}\n",
        "\n",
        "batch_predict_job_name = common_util.get_job_name_with_datetime(\n",
        "    prefix=f\"batch-predict-{MODEL_ID}\"\n",
        ")\n",
        "\n",
        "bytes_batch_predict_job = models[\"model\"].batch_predict(\n",
        "    job_display_name=batch_predict_job_name,\n",
        "    gcs_source=os.path.join(\n",
        "        STAGING_BUCKET, batch_predict_prefix, f\"input/{instances_filename}\"\n",
        "    ),\n",
        "    gcs_destination_prefix=os.path.join(STAGING_BUCKET, batch_predict_prefix, \"output\"),\n",
        "    machine_type=\"n1-highmem-8\",\n",
        "    service_account=SERVICE_ACCOUNT,\n",
        ")\n",
        "\n",
        "bytes_batch_predict_job.wait()\n",
        "\n",
        "print(bytes_batch_predict_job.display_name)\n",
        "print(bytes_batch_predict_job.resource_name)\n",
        "print(bytes_batch_predict_job.state)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Dab340pBJpRJ"
      },
      "outputs": [],
      "source": [
        "# @title #### Generate embeddings in batch from text queries\n",
        "\n",
        "# @markdown This section shows an example of generating embeddings in batch from text queries.\n",
        "\n",
        "# @markdown Each line in the input JSON Lines file is a prediction request instance that contains the following field:\n",
        "# @markdown - `prompt_query`: Text query string\n",
        "\n",
        "# @markdown Click \"Show Code\" to see more details.\n",
        "\n",
        "PROMPT_QUERIES = \"Airspace opacity\"  # @param {type:\"string\", placeholder:\"Comma-separated list of text query strings\"}\n",
        "\n",
        "prompt_queries_list = PROMPT_QUERIES.split(\",\")\n",
        "batch_predict_instances = [{\"prompt_query\": query} for query in prompt_queries_list]\n",
        "\n",
        "# Write instances to JSON Lines file\n",
        "os.makedirs(\"batch_predict_input\", exist_ok=True)\n",
        "instances_filename = \"text_instances.jsonl\"\n",
        "with open(f\"batch_predict_input/{instances_filename}\", \"w\") as f:\n",
        "    for line in batch_predict_instances:\n",
        "        json_str = json.dumps(line)\n",
        "        f.write(json_str)\n",
        "        f.write(\"\\n\")\n",
        "\n",
        "# Copy the file to Cloud Storage\n",
        "batch_predict_prefix = f\"batch-predict-{MODEL_ID}\"\n",
        "! gcloud storage cp ./batch_predict_input/{instances_filename} {STAGING_BUCKET}/{batch_predict_prefix}/input/{instances_filename}\n",
        "\n",
        "batch_predict_job_name = common_util.get_job_name_with_datetime(\n",
        "    prefix=f\"batch-predict-{MODEL_ID}\"\n",
        ")\n",
        "\n",
        "text_batch_predict_job = models[\"model\"].batch_predict(\n",
        "    job_display_name=batch_predict_job_name,\n",
        "    gcs_source=os.path.join(\n",
        "        STAGING_BUCKET, batch_predict_prefix, f\"input/{instances_filename}\"\n",
        "    ),\n",
        "    gcs_destination_prefix=os.path.join(STAGING_BUCKET, batch_predict_prefix, \"output\"),\n",
        "    machine_type=\"n1-highmem-8\",\n",
        "    service_account=SERVICE_ACCOUNT,\n",
        ")\n",
        "\n",
        "text_batch_predict_job.wait()\n",
        "\n",
        "print(text_batch_predict_job.display_name)\n",
        "print(text_batch_predict_job.resource_name)\n",
        "print(text_batch_predict_job.state)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "j80e0LiYXyRB"
      },
      "outputs": [],
      "source": [
        "# @title #### Get prediction results\n",
        "\n",
        "# @markdown Once the batch prediction job succeeds, you can [retrieve the results](https://cloud.google.com/vertex-ai/docs/predictions/get-batch-predictions#retrieve_batch_prediction_results)\n",
        "# @markdown from the JSON Lines file(s) in the output Cloud Storage location.\n",
        "\n",
        "# @markdown Click \"Show Code\" to see more details.\n",
        "\n",
        "\n",
        "def download_gcs_files_as_json(gcs_files_prefix):\n",
        "    \"\"\"Download specified files from Cloud Storage and convert content to JSON.\"\"\"\n",
        "    lines = []\n",
        "    client = storage.Client()\n",
        "    bucket = storage.bucket.Bucket.from_string(BUCKET_URI, client)\n",
        "    blobs = bucket.list_blobs(prefix=gcs_files_prefix)\n",
        "    for blob in blobs:\n",
        "        with blob.open(\"r\") as f:\n",
        "            for line in f:\n",
        "                lines.append(json.loads(line))\n",
        "    return lines\n",
        "\n",
        "\n",
        "# Get results from the first batch prediction job (with Cloud Storage image inputs)\n",
        "# You can replace these variable to get results from another batch prediction job\n",
        "batch_predict_job = gcs_batch_predict_job\n",
        "output_embedding_key = \"contrastive_img_emb\"\n",
        "\n",
        "batch_predict_output_dir = batch_predict_job.output_info.gcs_output_directory\n",
        "batch_predict_output_files_prefix = os.path.join(\n",
        "    batch_predict_output_dir.replace(f\"{BUCKET_URI}/\", \"\"), \"prediction.results\"\n",
        ")\n",
        "batch_predict_results = download_gcs_files_as_json(\n",
        "    gcs_files_prefix=batch_predict_output_files_prefix\n",
        ")\n",
        "\n",
        "# Display first two batch prediction results\n",
        "for i, line in enumerate(batch_predict_results[:2]):\n",
        "    embedding = np.array(line[\"prediction\"][output_embedding_key])\n",
        "\n",
        "    print(f\"Embedding shape {i}: \", embedding.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k3asO-u59c9Q"
      },
      "source": [
        "## Image attributions\n",
        "\n",
        "[1] The NIH Chest X-ray14 dataset consists of over 100,000 de-identified images of chest x-rays, with fourteen common disease labels, text-mined from the text radiological reports via NLP techniques.The dataset is available on the [NIH download site](https://nihcc.app.box.com/v/ChestXray-NIHCC) and on [Google Cloud](https://cloud.google.com/healthcare-api/docs/resources/public-datasets/nih-chest).\n",
        "\n",
        "\n",
        "[2] Stillwaterising, CC0, via Wikimedia Commons"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oXEmWgH4vjbm"
      },
      "source": [
        "## Next steps\n",
        "\n",
        "Explore the other [notebooks](https://github.com/google-health/cxr-foundation/blob/master/notebooks) to learn what else you can do with the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQMUmDYr6O_O"
      },
      "source": [
        "## Clean up resources"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "iOSY_r6mHYui"
      },
      "outputs": [],
      "source": [
        "# @markdown  Delete the experiment models and endpoints to recycle the resources\n",
        "# @markdown  and avoid unnecessary continuous charges that may incur.\n",
        "\n",
        "# Undeploy model and delete endpoint.\n",
        "for endpoint in endpoints.values():\n",
        "    endpoint.delete(force=True)\n",
        "\n",
        "# Delete models.\n",
        "for model in models.values():\n",
        "    model.delete()\n",
        "\n",
        "delete_bucket = False  # @param {type:\"boolean\"}\n",
        "if delete_bucket:\n",
        "    ! gsutil -m rm -r $BUCKET_NAME"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "quick_start_with_model_garden.ipynb",
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
